{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9IMZUWH66F1l"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-zcAL5N6PWj",
        "outputId": "c6a4f4f7-4e16-4120-8343-236a64a8c0e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance"
      ],
      "metadata": {
        "id": "h25ulsYP6XnF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx"
      ],
      "metadata": {
        "id": "X4NwkVTA6j7k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read(text):\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  return sentences\n"
      ],
      "metadata": {
        "id": "y86Zkwlt6opg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_similarity(sent1, sent2, stopwords = None):\n",
        "  if stopwords is None :\n",
        "    stopwords = []\n",
        "\n",
        "  sent1 = [w.lower() for w in sent1]\n",
        "  sent2 = [w.lower() for w in sent2]\n",
        "\n",
        "  all_words = list(set(sent1 + sent2))\n",
        "\n",
        "  vector1 = [0] * len(all_words)\n",
        "  vector2 = [0] * len(all_words)\n",
        "\n",
        "  for w in sent2 :\n",
        "    if w in stopwords :\n",
        "      continue\n",
        "    vector1[all_words.index(w)] += 1\n",
        "\n",
        "  for w in sent2 :\n",
        "    if w in stopwords :\n",
        "      continue\n",
        "    vector2[all_words.index(w)] += 1\n",
        "\n",
        "  return 1 - cosine_distance(vector1, vector2)"
      ],
      "metadata": {
        "id": "YJz2WLBQ623F"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_similarity_matrix(sentences, stop_words):\n",
        "  similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "  for idx1 in range(len(sentences)):\n",
        "    for idx2 in range(len(sentences)) :\n",
        "      if idx1 == idx2:\n",
        "        continue\n",
        "      similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "  return similarity_matrix"
      ],
      "metadata": {
        "id": "eESfGoFG770J"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text, num_sentences=5):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    summarize_text = []\n",
        "\n",
        "    sentences = read(text)\n",
        "    sentence_similarity_matrix = build_similarity_matrix(sentences, stop_words)\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "    for i in range(num_sentences):\n",
        "        summarize_text.append(ranked_sentences[i][1])\n",
        "\n",
        "    return ' '.join(summarize_text)"
      ],
      "metadata": {
        "id": "LqCnXeJq8zA7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The leather jacked showed the scars of being his favorite for years. It wore those scars with pride, feeling that they enhanced his presence rather than diminishing it. The scars gave it character and had not overwhelmed to the point that it had become ratty. The jacket was in its prime and it knew it.\""
      ],
      "metadata": {
        "id": "dBx1hz7K85fr"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = generate_summary(text, num_sentences = 1)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T18hSEsC9Dxh",
        "outputId": "4edcfc11-e012-40d4-e80f-fc2d60cb0f31"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scars gave it character and had not overwhelmed to the point that it had become ratty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woc29gg49MkO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}